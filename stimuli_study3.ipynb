{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use the stimuli of study 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dat = pd.read_csv('final_data_2.csv')\n",
    "df = pd.DataFrame(dat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "filtered_df = df[(df['test_part'].isin(['cs'])) & (df['skew'].isin(['lr', 'rl', 'ns'])) & (df['Prolific_ID'].isin(['5638e8a444e8c8000ee86a35']))]\n",
    "\n",
    "# Define the skewness calculation function\n",
    "def calculate_skewness(probabilities, outcomes):\n",
    "    # Mean (expected value)\n",
    "    mu = np.sum(outcomes * probabilities)\n",
    "    \n",
    "    # Variance\n",
    "    sigma_squared = np.sum((outcomes**2) * probabilities) - mu**2\n",
    "    \n",
    "    # Third Central Moment\n",
    "    mu_3 = np.sum(((outcomes - mu)**3) * probabilities)\n",
    "    \n",
    "    # Skewness\n",
    "    skewness = mu_3 / (sigma_squared**(3/2)) if sigma_squared != 0 else 0  # To handle division by zero\n",
    "    \n",
    "    return skewness\n",
    "\n",
    "\n",
    "selected_columns = ['skew', 'P_A1', 'O_A1', 'P_A2', 'O_A2', 'P_B1', 'O_B1', 'P_B2', 'O_B2']\n",
    "filtered_df = filtered_df[selected_columns]\n",
    "\n",
    "\n",
    "\n",
    "final_df = filtered_df.assign(\n",
    "    EVA=lambda x: x['P_A1'] * x['O_A1'] + x['P_A2'] * x['O_A2'],\n",
    "    EVB=lambda x: x['P_B1'] * x['O_B1'] + x['P_B2'] * x['O_B2'],\n",
    "    EVD=lambda x: x['EVA'] - x['EVB'],\n",
    "    SDA=lambda x: np.sqrt(x['P_A1'] * (x['O_A1'] - x['EVA'])**2 + x['P_A2'] * (x['O_A2'] - x['EVA'])**2),\n",
    "    SDB=lambda x: np.sqrt(x['P_B1'] * (x['O_B1'] - x['EVB'])**2 + x['P_B2'] * (x['O_B2'] - x['EVB'])**2),\n",
    "    SDD=lambda x: x['SDA'] - x['SDB'],\n",
    "    skewness_a=lambda x: x.apply(lambda row: calculate_skewness(\n",
    "        np.array([row['P_A1'], row['P_A2']]), \n",
    "        np.array([row['O_A1'], row['O_A2']])\n",
    "    ), axis=1),\n",
    "    skewness_b=lambda x: x.apply(lambda row: calculate_skewness(\n",
    "        np.array([row['P_B1'], row['P_B2']]), \n",
    "        np.array([row['O_B1'], row['O_B2']])\n",
    "    ), axis=1),\n",
    "    skewness_diff=lambda x: x['skewness_a'] - x['skewness_b']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Bin the 'EVD' column\n",
    "final_df['evd_bins'] = pd.cut(\n",
    "    final_df['EVD'], \n",
    "    bins=[-float('inf'), -15, -9, 1, 11, 21], \n",
    "    labels=[\"-21 to -19\", \"-11 to -9\", \"-1 to 1\", \"9 to 11\", \"19 to 21\"],\n",
    "    right=True,\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Bin the 'SDD' column\n",
    "final_df['sdd_bins'] = pd.cut(\n",
    "    final_df['SDD'], \n",
    "    bins=[-float('inf'), 8, 13, 18], \n",
    "    labels=[\"4 to 6\", \"9 to 11\", \"14 to 16\"],\n",
    "    right=True,\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by 'evd_bins' and then 'sdd_bins'\n",
    "final_df = final_df.sort_values(by=['evd_bins', 'sdd_bins'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Reset the index to remove the existing one and create a new sequential index\n",
    "final_df = final_df.reset_index(drop=True)\n",
    "\n",
    "# Add a new 'index' column starting from 1 to 45\n",
    "final_df['index'] = range(1, 46)\n",
    "\n",
    "# Move the 'index' column to the beginning of the DataFrame\n",
    "final_df = final_df[['index'] + [col for col in final_df.columns if col != 'index']]\n",
    "\n",
    "final_df_new = final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "random.seed(42)  # Set the random seed\n",
    "\n",
    "\n",
    "# Function to calculate skewness\n",
    "def calculate_skewness(probabilities, outcomes):\n",
    "    mu = np.sum(outcomes * probabilities)\n",
    "    sigma_squared = np.sum((outcomes**2) * probabilities) - mu**2\n",
    "    sigma = np.sqrt(sigma_squared)\n",
    "    mu_3 = np.sum(((outcomes - mu)**3) * probabilities)\n",
    "    skewness = mu_3 / (sigma**3) if sigma != 0 else 0\n",
    "    return skewness\n",
    "\n",
    "# Function to calculate EV, SD, and skewness\n",
    "def lottery_stats(probs, outcomes):\n",
    "    ev = np.sum(probs * outcomes)\n",
    "    sd = np.sqrt(np.sum(probs * (outcomes - ev) ** 2))\n",
    "    skw = calculate_skewness(probs, outcomes)\n",
    "    return ev, sd, skw\n",
    "\n",
    "# Generate unique probabilities that sum to 1\n",
    "def generate_unique_probs(n, low=0.02, high=0.4):\n",
    "    possible_probs = np.arange(low, high + 0.001, 0.01)\n",
    "    possible_probs = np.round(possible_probs, 2)\n",
    "    possible_probs = possible_probs[(possible_probs >= low) & (possible_probs <= high)]\n",
    "    # Remove duplicates due to rounding\n",
    "    possible_probs = np.unique(possible_probs)\n",
    "    # Ensure there are enough unique probabilities\n",
    "    if len(possible_probs) < n:\n",
    "        raise ValueError(\"Not enough unique probabilities within the specified bounds.\")\n",
    "    for _ in range(1000):  # Maximum attempts\n",
    "        probs = np.random.choice(possible_probs, size=n, replace=False)\n",
    "        probs = probs / probs.sum()\n",
    "        probs = np.round(probs, 2)\n",
    "        probs[-1] += 1 - probs.sum()  # Adjust to sum to 1\n",
    "        # Check for uniqueness after rounding and adjustment\n",
    "        if np.all(probs >= low) and np.all(probs <= high) and len(np.unique(probs)) == n:\n",
    "            return probs\n",
    "    raise ValueError(\"Unable to generate unique probabilities within bounds after rounding.\")\n",
    "\n",
    "# Optimization function\n",
    "def optimize_lottery(original_probs, original_outcomes):\n",
    "    # Original lottery statistics\n",
    "    original_ev = np.sum(original_probs * original_outcomes)\n",
    "    original_sd = np.sqrt(np.sum(original_probs * (original_outcomes - original_ev) ** 2))\n",
    "    original_skew = calculate_skewness(original_probs, original_outcomes)\n",
    "\n",
    "    # Parameters\n",
    "    n = 7  # Number of outcomes\n",
    "    iterations = 200  # Number of iterations to run\n",
    "    delta = 2  # Minimum difference to ensure uniqueness after rounding\n",
    "    max_gap = 50  # Maximum allowed gap between consecutive outcomes\n",
    "    gap_weight = 0.01  # Weight for the gap penalty in the objective function\n",
    "\n",
    "    # Bounds for outcomes\n",
    "    bounds = [(2, 200)] * n\n",
    "\n",
    "    # List to store acceptable results\n",
    "    acceptable_results = []\n",
    "\n",
    "    # Run the optimization multiple times\n",
    "    for iteration in range(iterations):\n",
    "        # Generate unique probabilities\n",
    "        try:\n",
    "            fixed_probs = generate_unique_probs(n)\n",
    "        except ValueError:\n",
    "            continue  # Skip if unable to generate probabilities\n",
    "\n",
    "        # Desired average gap between outcomes\n",
    "        desired_gap = (bounds[0][1] - bounds[0][0]) / (n - 1)\n",
    "\n",
    "        # Objective function with gap penalty\n",
    "        def objective_outcomes(outcomes):\n",
    "            ev, sd, skw = lottery_stats(fixed_probs, outcomes)\n",
    "            penalty_stats = (ev - original_ev)**2 + (sd - original_sd)**2 + (skw - original_skew)**2\n",
    "            penalty_gaps = np.sum((np.diff(outcomes) + desired_gap)**2)  # Adjusted for decreasing order\n",
    "            penalty = penalty_stats + gap_weight * penalty_gaps\n",
    "            return penalty\n",
    "\n",
    "        # Initial guess for outcomes (from high to low)\n",
    "        initial_outcomes = np.linspace(bounds[0][1], bounds[0][0], n)\n",
    "\n",
    "        # Constraints to ensure outcomes are decreasing and gaps are within limits\n",
    "        constraints = [\n",
    "            {'type': 'ineq', 'fun': lambda x, i=i: x[i] - x[i+1] - delta} for i in range(n - 1)\n",
    "        ] + [\n",
    "            {'type': 'ineq', 'fun': lambda x, i=i: max_gap - (x[i] - x[i+1])} for i in range(n - 1)\n",
    "        ]\n",
    "\n",
    "        # Optimize outcomes\n",
    "        result = minimize(\n",
    "            objective_outcomes,\n",
    "            initial_outcomes,\n",
    "            bounds=bounds,\n",
    "            constraints=constraints,\n",
    "            method='SLSQP',\n",
    "            options={'ftol': 1e-9, 'disp': False}\n",
    "        )\n",
    "\n",
    "        # Check if the optimization was successful\n",
    "        if not result.success:\n",
    "            continue  # Skip this iteration if optimization failed\n",
    "\n",
    "        # Extract optimized outcomes\n",
    "        optimized_outcomes = np.round(result.x).astype(int)\n",
    "\n",
    "        # Adjust outcomes to ensure uniqueness after rounding and maintain gaps\n",
    "        for i in range(1, n):\n",
    "            # Ensure the gap does not exceed max_gap\n",
    "            if optimized_outcomes[i - 1] - optimized_outcomes[i] > max_gap:\n",
    "                optimized_outcomes[i] = optimized_outcomes[i - 1] - max_gap\n",
    "            # Ensure outcomes are decreasing by at least delta\n",
    "            if optimized_outcomes[i] >= optimized_outcomes[i - 1]:\n",
    "                optimized_outcomes[i] = optimized_outcomes[i - 1] - int(delta)\n",
    "            # Ensure within bounds\n",
    "            if optimized_outcomes[i] < bounds[i][0]:\n",
    "                optimized_outcomes[i] = bounds[i][0]\n",
    "\n",
    "        # Recalculate the statistics with adjusted outcomes\n",
    "        final_ev, final_sd, final_skew = lottery_stats(fixed_probs, optimized_outcomes)\n",
    "\n",
    "        # Check if the differences in EV and SD are less than 1\n",
    "        if abs(final_ev - original_ev) < 1 and abs(final_sd - original_sd) < 1:\n",
    "            skewness_difference = abs(final_skew - original_skew)\n",
    "            # Store the acceptable results\n",
    "            acceptable_results.append({\n",
    "                'skewness_difference': skewness_difference,\n",
    "                'outcomes': optimized_outcomes.copy(),\n",
    "                'probabilities': fixed_probs.copy(),\n",
    "                'final_ev': final_ev,\n",
    "                'final_sd': final_sd,\n",
    "                'final_skew': final_skew,\n",
    "                'original_ev': original_ev,\n",
    "                'original_sd': original_sd,\n",
    "                'original_skew': original_skew\n",
    "            })\n",
    "\n",
    "    # After all iterations, select the best result based on minimal skewness difference\n",
    "    if acceptable_results:\n",
    "        # Sort the acceptable results by skewness_difference\n",
    "        acceptable_results.sort(key=lambda x: x['skewness_difference'])\n",
    "        best_result = acceptable_results[0]\n",
    "        # Extract the best results\n",
    "        best_outcomes = best_result['outcomes']\n",
    "        best_probs = best_result['probabilities']\n",
    "        final_ev = best_result['final_ev']\n",
    "        final_sd = best_result['final_sd']\n",
    "        final_skew = best_result['final_skew']\n",
    "        # Return the best results and statistics\n",
    "        return best_outcomes, best_probs, {\n",
    "            'original_ev': best_result['original_ev'],\n",
    "            'original_sd': best_result['original_sd'],\n",
    "            'original_skew': best_result['original_skew'],\n",
    "            'new_ev': final_ev,\n",
    "            'new_sd': final_sd,\n",
    "            'new_skew': final_skew\n",
    "        }\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "# Function to process each row of the DataFrame\n",
    "def process_row(row):\n",
    "    result_dict = {}\n",
    "    # For Lottery A\n",
    "    probs_A = np.array([row['P_A1'], row['P_A2']])\n",
    "    probs_A = probs_A / probs_A.sum()\n",
    "    outcomes_A = np.array([row['O_A1'], row['O_A2']])\n",
    "\n",
    "    # Original statistics for Lottery A\n",
    "    original_ev_A, original_sd_A, original_skew_A = lottery_stats(probs_A, outcomes_A)\n",
    "    result_dict['simple_EVA'] = original_ev_A\n",
    "    result_dict['simple_SDA'] = original_sd_A\n",
    "    result_dict['simple_skewness_A'] = original_skew_A\n",
    "\n",
    "    # Optimize Lottery A\n",
    "    best_outcomes_A, best_probs_A, stats_A = optimize_lottery(probs_A, outcomes_A)\n",
    "\n",
    "    if best_outcomes_A is not None:\n",
    "        # Store new outcomes and probabilities\n",
    "        for i in range(len(best_outcomes_A)):\n",
    "            result_dict[f'complex_OA{i+1}'] = int(best_outcomes_A[i])  # Ensure integer outcomes\n",
    "            result_dict[f'complex_PA{i+1}'] = best_probs_A[i]\n",
    "        # Store new statistics\n",
    "        result_dict['complex_EVA'] = stats_A['new_ev']\n",
    "        result_dict['complex_SDA'] = stats_A['new_sd']\n",
    "        result_dict['complex_skewness_A'] = stats_A['new_skew']\n",
    "    else:\n",
    "        for i in range(7):\n",
    "            result_dict[f'complex_OA{i+1}'] = np.nan\n",
    "            result_dict[f'complex_PA{i+1}'] = np.nan\n",
    "        result_dict['complex_EVA'] = np.nan\n",
    "        result_dict['complex_SDA'] = np.nan\n",
    "        result_dict['complex_skewness_A'] = np.nan\n",
    "\n",
    "    # For Lottery B\n",
    "    probs_B = np.array([row['P_B1'], row['P_B2']])\n",
    "    probs_B = probs_B / probs_B.sum()\n",
    "    outcomes_B = np.array([row['O_B1'], row['O_B2']])\n",
    "\n",
    "    # Original statistics for Lottery B\n",
    "    original_ev_B, original_sd_B, original_skew_B = lottery_stats(probs_B, outcomes_B)\n",
    "    result_dict['simple_EVB'] = original_ev_B\n",
    "    result_dict['simple_SDB'] = original_sd_B\n",
    "    result_dict['simple_skewness_B'] = original_skew_B\n",
    "\n",
    "    # Optimize Lottery B\n",
    "    best_outcomes_B, best_probs_B, stats_B = optimize_lottery(probs_B, outcomes_B)\n",
    "\n",
    "    if best_outcomes_B is not None:\n",
    "        # Store new outcomes and probabilities\n",
    "        for i in range(len(best_outcomes_B)):\n",
    "            result_dict[f'complex_OB{i+1}'] = int(best_outcomes_B[i])  # Ensure integer outcomes\n",
    "            result_dict[f'complex_PB{i+1}'] = best_probs_B[i]\n",
    "        # Store new statistics\n",
    "        result_dict['complex_EVB'] = stats_B['new_ev']\n",
    "        result_dict['complex_SDB'] = stats_B['new_sd']\n",
    "        result_dict['complex_skewness_B'] = stats_B['new_skew']\n",
    "    else:\n",
    "        for i in range(7):\n",
    "            result_dict[f'complex_OB{i+1}'] = np.nan\n",
    "            result_dict[f'complex_PB{i+1}'] = np.nan\n",
    "        result_dict['complex_EVB'] = np.nan\n",
    "        result_dict['complex_SDB'] = np.nan\n",
    "        result_dict['complex_skewness_B'] = np.nan\n",
    "\n",
    "    # Differences between Lotteries A and B (Original)\n",
    "    result_dict['simple_EVD'] = result_dict['simple_EVA'] - result_dict['simple_EVB']\n",
    "    result_dict['simple_SDD'] = result_dict['simple_SDA'] - result_dict['simple_SDB']\n",
    "    result_dict['simple_skewness_D'] = result_dict['simple_skewness_A'] - result_dict['simple_skewness_B']\n",
    "\n",
    "    # Differences between Lotteries A and B (New)\n",
    "    if best_outcomes_A is not None and best_outcomes_B is not None:\n",
    "        result_dict['complex_EVD'] = result_dict['complex_EVA'] - result_dict['complex_EVB']\n",
    "        result_dict['complex_SDD'] = result_dict['complex_SDA'] - result_dict['complex_SDB']\n",
    "        result_dict['complex_skewness_D'] = result_dict['complex_skewness_A'] - result_dict['complex_skewness_B']\n",
    "    else:\n",
    "        result_dict['complex_EVD'] = np.nan\n",
    "        result_dict['complex_SDD'] = np.nan\n",
    "        result_dict['complex_skewness_D'] = np.nan\n",
    "\n",
    "    return pd.Series(result_dict)\n",
    "\n",
    "# Apply the process_row function to each row\n",
    "new_columns = final_df_new.apply(process_row, axis=1)\n",
    "\n",
    "# Concatenate the new columns to the original DataFrame\n",
    "final_df_new = pd.concat([final_df_new, new_columns], axis=1)\n",
    "\n",
    "# Convert outcome columns to nullable integer type\n",
    "outcome_columns = [f'complex_OA{i+1}' for i in range(7)] + [f'complex_OB{i+1}' for i in range(7)]\n",
    "final_df_new[outcome_columns] = final_df_new[outcome_columns].astype('Int64')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jl/mx4l1z1j1kgd53hpj7770jlw0000gp/T/ipykernel_75417/1049243912.py:21: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_selected_rounded = df_selected.applymap(lambda x: round(x, 2) if isinstance(x, (int, float)) else x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skew</th>\n",
       "      <th>EVA</th>\n",
       "      <th>EVB</th>\n",
       "      <th>EVD</th>\n",
       "      <th>complex_EVA</th>\n",
       "      <th>complex_EVB</th>\n",
       "      <th>complex_EVD</th>\n",
       "      <th>SDA</th>\n",
       "      <th>SDB</th>\n",
       "      <th>SDD</th>\n",
       "      <th>complex_SDA</th>\n",
       "      <th>complex_SDB</th>\n",
       "      <th>complex_SDD</th>\n",
       "      <th>simple_skewness_A</th>\n",
       "      <th>complex_skewness_A</th>\n",
       "      <th>simple_skewness_B</th>\n",
       "      <th>complex_skewness_B</th>\n",
       "      <th>simple_skewness_D</th>\n",
       "      <th>complex_skewness_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lr</td>\n",
       "      <td>82.34</td>\n",
       "      <td>91.96</td>\n",
       "      <td>-9.62</td>\n",
       "      <td>82.15</td>\n",
       "      <td>91.97</td>\n",
       "      <td>-9.82</td>\n",
       "      <td>33.42</td>\n",
       "      <td>18.85</td>\n",
       "      <td>14.58</td>\n",
       "      <td>33.69</td>\n",
       "      <td>19.53</td>\n",
       "      <td>14.16</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>-2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>lr</td>\n",
       "      <td>41.40</td>\n",
       "      <td>31.55</td>\n",
       "      <td>9.85</td>\n",
       "      <td>41.35</td>\n",
       "      <td>31.55</td>\n",
       "      <td>9.80</td>\n",
       "      <td>15.69</td>\n",
       "      <td>5.63</td>\n",
       "      <td>10.06</td>\n",
       "      <td>16.34</td>\n",
       "      <td>6.60</td>\n",
       "      <td>9.75</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.78</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>-2.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lr</td>\n",
       "      <td>71.72</td>\n",
       "      <td>71.97</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>71.54</td>\n",
       "      <td>71.81</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>18.04</td>\n",
       "      <td>8.45</td>\n",
       "      <td>9.60</td>\n",
       "      <td>18.59</td>\n",
       "      <td>9.34</td>\n",
       "      <td>9.26</td>\n",
       "      <td>-2.08</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.41</td>\n",
       "      <td>-4.57</td>\n",
       "      <td>-3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lr</td>\n",
       "      <td>117.66</td>\n",
       "      <td>127.23</td>\n",
       "      <td>-9.57</td>\n",
       "      <td>117.62</td>\n",
       "      <td>127.24</td>\n",
       "      <td>-9.62</td>\n",
       "      <td>33.74</td>\n",
       "      <td>23.88</td>\n",
       "      <td>9.86</td>\n",
       "      <td>34.15</td>\n",
       "      <td>24.51</td>\n",
       "      <td>9.64</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.47</td>\n",
       "      <td>-3.78</td>\n",
       "      <td>-2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>lr</td>\n",
       "      <td>68.00</td>\n",
       "      <td>47.42</td>\n",
       "      <td>20.58</td>\n",
       "      <td>67.93</td>\n",
       "      <td>47.34</td>\n",
       "      <td>20.59</td>\n",
       "      <td>24.37</td>\n",
       "      <td>9.77</td>\n",
       "      <td>14.61</td>\n",
       "      <td>25.01</td>\n",
       "      <td>10.53</td>\n",
       "      <td>14.49</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.63</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>-2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>lr</td>\n",
       "      <td>83.35</td>\n",
       "      <td>63.36</td>\n",
       "      <td>19.99</td>\n",
       "      <td>83.50</td>\n",
       "      <td>63.64</td>\n",
       "      <td>19.86</td>\n",
       "      <td>16.90</td>\n",
       "      <td>12.25</td>\n",
       "      <td>4.66</td>\n",
       "      <td>17.50</td>\n",
       "      <td>13.01</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.59</td>\n",
       "      <td>-5.13</td>\n",
       "      <td>-4.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lr</td>\n",
       "      <td>51.33</td>\n",
       "      <td>60.88</td>\n",
       "      <td>-9.55</td>\n",
       "      <td>51.43</td>\n",
       "      <td>60.94</td>\n",
       "      <td>-9.51</td>\n",
       "      <td>19.16</td>\n",
       "      <td>14.11</td>\n",
       "      <td>5.05</td>\n",
       "      <td>19.95</td>\n",
       "      <td>14.56</td>\n",
       "      <td>5.39</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>4.69</td>\n",
       "      <td>3.12</td>\n",
       "      <td>-6.45</td>\n",
       "      <td>-4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lr</td>\n",
       "      <td>93.48</td>\n",
       "      <td>113.01</td>\n",
       "      <td>-19.53</td>\n",
       "      <td>93.29</td>\n",
       "      <td>113.06</td>\n",
       "      <td>-19.77</td>\n",
       "      <td>34.98</td>\n",
       "      <td>19.91</td>\n",
       "      <td>15.07</td>\n",
       "      <td>35.10</td>\n",
       "      <td>20.72</td>\n",
       "      <td>14.39</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-3.96</td>\n",
       "      <td>-2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>lr</td>\n",
       "      <td>89.33</td>\n",
       "      <td>89.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>89.46</td>\n",
       "      <td>89.28</td>\n",
       "      <td>0.18</td>\n",
       "      <td>19.84</td>\n",
       "      <td>4.77</td>\n",
       "      <td>15.08</td>\n",
       "      <td>20.62</td>\n",
       "      <td>5.71</td>\n",
       "      <td>14.91</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.93</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>-3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>lr</td>\n",
       "      <td>64.82</td>\n",
       "      <td>45.36</td>\n",
       "      <td>19.46</td>\n",
       "      <td>64.59</td>\n",
       "      <td>45.55</td>\n",
       "      <td>19.04</td>\n",
       "      <td>19.59</td>\n",
       "      <td>9.10</td>\n",
       "      <td>10.49</td>\n",
       "      <td>20.20</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.20</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.26</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>-3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lr</td>\n",
       "      <td>41.98</td>\n",
       "      <td>31.75</td>\n",
       "      <td>10.23</td>\n",
       "      <td>42.01</td>\n",
       "      <td>31.74</td>\n",
       "      <td>10.27</td>\n",
       "      <td>14.98</td>\n",
       "      <td>9.81</td>\n",
       "      <td>5.18</td>\n",
       "      <td>15.74</td>\n",
       "      <td>10.61</td>\n",
       "      <td>5.12</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.53</td>\n",
       "      <td>-3.25</td>\n",
       "      <td>-2.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lr</td>\n",
       "      <td>93.89</td>\n",
       "      <td>114.40</td>\n",
       "      <td>-20.51</td>\n",
       "      <td>93.74</td>\n",
       "      <td>114.55</td>\n",
       "      <td>-20.81</td>\n",
       "      <td>31.18</td>\n",
       "      <td>20.82</td>\n",
       "      <td>10.36</td>\n",
       "      <td>31.65</td>\n",
       "      <td>21.53</td>\n",
       "      <td>10.12</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.27</td>\n",
       "      <td>-3.83</td>\n",
       "      <td>-2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>lr</td>\n",
       "      <td>77.88</td>\n",
       "      <td>67.73</td>\n",
       "      <td>10.15</td>\n",
       "      <td>77.95</td>\n",
       "      <td>67.37</td>\n",
       "      <td>10.58</td>\n",
       "      <td>24.70</td>\n",
       "      <td>9.95</td>\n",
       "      <td>14.75</td>\n",
       "      <td>25.20</td>\n",
       "      <td>10.78</td>\n",
       "      <td>14.42</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.58</td>\n",
       "      <td>-5.71</td>\n",
       "      <td>-3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr</td>\n",
       "      <td>82.96</td>\n",
       "      <td>102.72</td>\n",
       "      <td>-19.76</td>\n",
       "      <td>83.07</td>\n",
       "      <td>102.79</td>\n",
       "      <td>-19.72</td>\n",
       "      <td>29.84</td>\n",
       "      <td>24.56</td>\n",
       "      <td>5.28</td>\n",
       "      <td>30.20</td>\n",
       "      <td>25.08</td>\n",
       "      <td>5.12</td>\n",
       "      <td>-2.08</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.31</td>\n",
       "      <td>-3.93</td>\n",
       "      <td>-2.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lr</td>\n",
       "      <td>48.94</td>\n",
       "      <td>49.10</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>48.80</td>\n",
       "      <td>48.83</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>9.73</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.53</td>\n",
       "      <td>10.47</td>\n",
       "      <td>6.15</td>\n",
       "      <td>4.32</td>\n",
       "      <td>-2.87</td>\n",
       "      <td>-2.16</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.07</td>\n",
       "      <td>-4.94</td>\n",
       "      <td>-4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ns</td>\n",
       "      <td>43.79</td>\n",
       "      <td>44.12</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>43.53</td>\n",
       "      <td>44.12</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>17.40</td>\n",
       "      <td>12.62</td>\n",
       "      <td>4.78</td>\n",
       "      <td>18.13</td>\n",
       "      <td>13.32</td>\n",
       "      <td>4.81</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ns</td>\n",
       "      <td>109.57</td>\n",
       "      <td>109.23</td>\n",
       "      <td>0.34</td>\n",
       "      <td>109.32</td>\n",
       "      <td>109.56</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>84.35</td>\n",
       "      <td>69.75</td>\n",
       "      <td>14.60</td>\n",
       "      <td>83.41</td>\n",
       "      <td>69.37</td>\n",
       "      <td>14.03</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ns</td>\n",
       "      <td>62.12</td>\n",
       "      <td>52.18</td>\n",
       "      <td>9.94</td>\n",
       "      <td>62.21</td>\n",
       "      <td>52.10</td>\n",
       "      <td>10.11</td>\n",
       "      <td>23.83</td>\n",
       "      <td>8.47</td>\n",
       "      <td>15.35</td>\n",
       "      <td>24.46</td>\n",
       "      <td>9.29</td>\n",
       "      <td>15.18</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ns</td>\n",
       "      <td>65.40</td>\n",
       "      <td>55.60</td>\n",
       "      <td>9.80</td>\n",
       "      <td>65.44</td>\n",
       "      <td>55.55</td>\n",
       "      <td>9.89</td>\n",
       "      <td>14.66</td>\n",
       "      <td>9.66</td>\n",
       "      <td>5.01</td>\n",
       "      <td>15.51</td>\n",
       "      <td>10.52</td>\n",
       "      <td>4.99</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ns</td>\n",
       "      <td>79.12</td>\n",
       "      <td>79.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>79.32</td>\n",
       "      <td>79.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>67.12</td>\n",
       "      <td>56.91</td>\n",
       "      <td>10.21</td>\n",
       "      <td>67.02</td>\n",
       "      <td>56.97</td>\n",
       "      <td>10.05</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ns</td>\n",
       "      <td>92.48</td>\n",
       "      <td>103.20</td>\n",
       "      <td>-10.72</td>\n",
       "      <td>93.28</td>\n",
       "      <td>103.41</td>\n",
       "      <td>-10.13</td>\n",
       "      <td>66.02</td>\n",
       "      <td>51.51</td>\n",
       "      <td>14.51</td>\n",
       "      <td>65.25</td>\n",
       "      <td>51.90</td>\n",
       "      <td>13.35</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ns</td>\n",
       "      <td>103.35</td>\n",
       "      <td>113.00</td>\n",
       "      <td>-9.65</td>\n",
       "      <td>102.93</td>\n",
       "      <td>112.72</td>\n",
       "      <td>-9.79</td>\n",
       "      <td>71.14</td>\n",
       "      <td>61.24</td>\n",
       "      <td>9.90</td>\n",
       "      <td>70.25</td>\n",
       "      <td>61.48</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ns</td>\n",
       "      <td>120.34</td>\n",
       "      <td>100.48</td>\n",
       "      <td>19.86</td>\n",
       "      <td>120.00</td>\n",
       "      <td>100.76</td>\n",
       "      <td>19.24</td>\n",
       "      <td>76.21</td>\n",
       "      <td>66.02</td>\n",
       "      <td>10.19</td>\n",
       "      <td>75.89</td>\n",
       "      <td>65.75</td>\n",
       "      <td>10.15</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ns</td>\n",
       "      <td>37.92</td>\n",
       "      <td>47.60</td>\n",
       "      <td>-9.68</td>\n",
       "      <td>38.54</td>\n",
       "      <td>48.13</td>\n",
       "      <td>-9.59</td>\n",
       "      <td>34.56</td>\n",
       "      <td>29.90</td>\n",
       "      <td>4.66</td>\n",
       "      <td>34.45</td>\n",
       "      <td>29.78</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ns</td>\n",
       "      <td>48.36</td>\n",
       "      <td>68.61</td>\n",
       "      <td>-20.25</td>\n",
       "      <td>48.76</td>\n",
       "      <td>68.63</td>\n",
       "      <td>-19.87</td>\n",
       "      <td>28.63</td>\n",
       "      <td>13.37</td>\n",
       "      <td>15.26</td>\n",
       "      <td>28.97</td>\n",
       "      <td>13.91</td>\n",
       "      <td>15.06</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ns</td>\n",
       "      <td>44.20</td>\n",
       "      <td>64.67</td>\n",
       "      <td>-20.47</td>\n",
       "      <td>44.10</td>\n",
       "      <td>64.61</td>\n",
       "      <td>-20.51</td>\n",
       "      <td>25.47</td>\n",
       "      <td>15.35</td>\n",
       "      <td>10.13</td>\n",
       "      <td>25.97</td>\n",
       "      <td>16.28</td>\n",
       "      <td>9.69</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ns</td>\n",
       "      <td>80.95</td>\n",
       "      <td>60.88</td>\n",
       "      <td>20.07</td>\n",
       "      <td>81.63</td>\n",
       "      <td>60.94</td>\n",
       "      <td>20.69</td>\n",
       "      <td>51.64</td>\n",
       "      <td>36.69</td>\n",
       "      <td>14.95</td>\n",
       "      <td>50.86</td>\n",
       "      <td>36.92</td>\n",
       "      <td>13.94</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ns</td>\n",
       "      <td>53.68</td>\n",
       "      <td>73.64</td>\n",
       "      <td>-19.96</td>\n",
       "      <td>53.50</td>\n",
       "      <td>73.92</td>\n",
       "      <td>-20.42</td>\n",
       "      <td>31.06</td>\n",
       "      <td>25.58</td>\n",
       "      <td>5.48</td>\n",
       "      <td>31.75</td>\n",
       "      <td>26.03</td>\n",
       "      <td>5.72</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ns</td>\n",
       "      <td>88.04</td>\n",
       "      <td>67.80</td>\n",
       "      <td>20.24</td>\n",
       "      <td>88.08</td>\n",
       "      <td>68.03</td>\n",
       "      <td>20.05</td>\n",
       "      <td>52.42</td>\n",
       "      <td>47.16</td>\n",
       "      <td>5.26</td>\n",
       "      <td>52.73</td>\n",
       "      <td>47.13</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ns</td>\n",
       "      <td>54.11</td>\n",
       "      <td>43.55</td>\n",
       "      <td>10.56</td>\n",
       "      <td>54.53</td>\n",
       "      <td>44.00</td>\n",
       "      <td>10.53</td>\n",
       "      <td>49.73</td>\n",
       "      <td>39.30</td>\n",
       "      <td>10.43</td>\n",
       "      <td>49.41</td>\n",
       "      <td>39.15</td>\n",
       "      <td>10.26</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>rl</td>\n",
       "      <td>128.94</td>\n",
       "      <td>109.07</td>\n",
       "      <td>19.87</td>\n",
       "      <td>128.77</td>\n",
       "      <td>109.29</td>\n",
       "      <td>19.48</td>\n",
       "      <td>30.80</td>\n",
       "      <td>25.26</td>\n",
       "      <td>5.54</td>\n",
       "      <td>31.36</td>\n",
       "      <td>25.81</td>\n",
       "      <td>5.55</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-3.37</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>5.13</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>rl</td>\n",
       "      <td>107.68</td>\n",
       "      <td>88.16</td>\n",
       "      <td>19.52</td>\n",
       "      <td>107.54</td>\n",
       "      <td>88.07</td>\n",
       "      <td>19.47</td>\n",
       "      <td>29.20</td>\n",
       "      <td>18.52</td>\n",
       "      <td>10.68</td>\n",
       "      <td>29.75</td>\n",
       "      <td>19.37</td>\n",
       "      <td>10.39</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>rl</td>\n",
       "      <td>104.88</td>\n",
       "      <td>95.17</td>\n",
       "      <td>9.71</td>\n",
       "      <td>104.97</td>\n",
       "      <td>95.29</td>\n",
       "      <td>9.68</td>\n",
       "      <td>32.17</td>\n",
       "      <td>17.61</td>\n",
       "      <td>14.57</td>\n",
       "      <td>32.44</td>\n",
       "      <td>18.38</td>\n",
       "      <td>14.06</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.31</td>\n",
       "      <td>-3.37</td>\n",
       "      <td>-2.13</td>\n",
       "      <td>5.71</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rl</td>\n",
       "      <td>89.78</td>\n",
       "      <td>110.56</td>\n",
       "      <td>-20.78</td>\n",
       "      <td>89.97</td>\n",
       "      <td>110.59</td>\n",
       "      <td>-20.62</td>\n",
       "      <td>44.07</td>\n",
       "      <td>39.96</td>\n",
       "      <td>4.11</td>\n",
       "      <td>44.18</td>\n",
       "      <td>40.44</td>\n",
       "      <td>3.74</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rl</td>\n",
       "      <td>111.24</td>\n",
       "      <td>101.12</td>\n",
       "      <td>10.12</td>\n",
       "      <td>111.12</td>\n",
       "      <td>101.17</td>\n",
       "      <td>9.95</td>\n",
       "      <td>26.12</td>\n",
       "      <td>20.40</td>\n",
       "      <td>5.73</td>\n",
       "      <td>26.85</td>\n",
       "      <td>21.13</td>\n",
       "      <td>5.72</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.64</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rl</td>\n",
       "      <td>84.62</td>\n",
       "      <td>84.52</td>\n",
       "      <td>0.10</td>\n",
       "      <td>84.62</td>\n",
       "      <td>84.50</td>\n",
       "      <td>0.12</td>\n",
       "      <td>24.89</td>\n",
       "      <td>10.26</td>\n",
       "      <td>14.62</td>\n",
       "      <td>25.25</td>\n",
       "      <td>11.18</td>\n",
       "      <td>14.07</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>-1.82</td>\n",
       "      <td>4.06</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rl</td>\n",
       "      <td>60.96</td>\n",
       "      <td>61.82</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>60.79</td>\n",
       "      <td>61.89</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>22.21</td>\n",
       "      <td>11.89</td>\n",
       "      <td>10.32</td>\n",
       "      <td>22.88</td>\n",
       "      <td>12.74</td>\n",
       "      <td>10.14</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.54</td>\n",
       "      <td>-2.49</td>\n",
       "      <td>-1.96</td>\n",
       "      <td>4.57</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rl</td>\n",
       "      <td>100.33</td>\n",
       "      <td>100.76</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>100.23</td>\n",
       "      <td>100.59</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>10.59</td>\n",
       "      <td>5.55</td>\n",
       "      <td>5.04</td>\n",
       "      <td>11.40</td>\n",
       "      <td>6.44</td>\n",
       "      <td>4.96</td>\n",
       "      <td>2.87</td>\n",
       "      <td>2.53</td>\n",
       "      <td>-2.08</td>\n",
       "      <td>-1.96</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rl</td>\n",
       "      <td>108.08</td>\n",
       "      <td>117.28</td>\n",
       "      <td>-9.20</td>\n",
       "      <td>107.97</td>\n",
       "      <td>117.34</td>\n",
       "      <td>-9.37</td>\n",
       "      <td>40.72</td>\n",
       "      <td>26.32</td>\n",
       "      <td>14.40</td>\n",
       "      <td>41.14</td>\n",
       "      <td>26.73</td>\n",
       "      <td>14.41</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>-1.61</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rl</td>\n",
       "      <td>73.98</td>\n",
       "      <td>84.53</td>\n",
       "      <td>-10.55</td>\n",
       "      <td>74.10</td>\n",
       "      <td>84.51</td>\n",
       "      <td>-10.41</td>\n",
       "      <td>16.48</td>\n",
       "      <td>6.39</td>\n",
       "      <td>10.09</td>\n",
       "      <td>17.20</td>\n",
       "      <td>7.15</td>\n",
       "      <td>10.05</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.54</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>-2.16</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rl</td>\n",
       "      <td>139.69</td>\n",
       "      <td>149.68</td>\n",
       "      <td>-9.99</td>\n",
       "      <td>139.73</td>\n",
       "      <td>149.80</td>\n",
       "      <td>-10.07</td>\n",
       "      <td>21.41</td>\n",
       "      <td>16.26</td>\n",
       "      <td>5.15</td>\n",
       "      <td>21.98</td>\n",
       "      <td>16.57</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.27</td>\n",
       "      <td>-4.69</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>6.45</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rl</td>\n",
       "      <td>56.71</td>\n",
       "      <td>76.26</td>\n",
       "      <td>-19.55</td>\n",
       "      <td>56.65</td>\n",
       "      <td>76.06</td>\n",
       "      <td>-19.41</td>\n",
       "      <td>22.53</td>\n",
       "      <td>8.26</td>\n",
       "      <td>14.27</td>\n",
       "      <td>23.03</td>\n",
       "      <td>9.21</td>\n",
       "      <td>13.82</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.45</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rl</td>\n",
       "      <td>72.43</td>\n",
       "      <td>92.74</td>\n",
       "      <td>-20.31</td>\n",
       "      <td>72.56</td>\n",
       "      <td>92.61</td>\n",
       "      <td>-20.05</td>\n",
       "      <td>29.67</td>\n",
       "      <td>20.47</td>\n",
       "      <td>9.20</td>\n",
       "      <td>30.17</td>\n",
       "      <td>21.07</td>\n",
       "      <td>9.10</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-2.08</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rl</td>\n",
       "      <td>124.15</td>\n",
       "      <td>114.46</td>\n",
       "      <td>9.69</td>\n",
       "      <td>124.34</td>\n",
       "      <td>114.45</td>\n",
       "      <td>9.89</td>\n",
       "      <td>33.35</td>\n",
       "      <td>23.29</td>\n",
       "      <td>10.06</td>\n",
       "      <td>33.68</td>\n",
       "      <td>23.82</td>\n",
       "      <td>9.85</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>rl</td>\n",
       "      <td>70.60</td>\n",
       "      <td>50.16</td>\n",
       "      <td>20.44</td>\n",
       "      <td>70.58</td>\n",
       "      <td>50.01</td>\n",
       "      <td>20.57</td>\n",
       "      <td>34.12</td>\n",
       "      <td>19.53</td>\n",
       "      <td>14.59</td>\n",
       "      <td>34.32</td>\n",
       "      <td>20.10</td>\n",
       "      <td>14.23</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.08</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   skew     EVA     EVB    EVD  complex_EVA  complex_EVB  complex_EVD    SDA  \\\n",
       "16   lr   82.34   91.96  -9.62        82.15        91.97        -9.82  33.42   \n",
       "31   lr   41.40   31.55   9.85        41.35        31.55         9.80  15.69   \n",
       "21   lr   71.72   71.97  -0.25        71.54        71.81        -0.27  18.04   \n",
       "14   lr  117.66  127.23  -9.57       117.62       127.24        -9.62  33.74   \n",
       "43   lr   68.00   47.42  20.58        67.93        47.34        20.59  24.37   \n",
       "36   lr   83.35   63.36  19.99        83.50        63.64        19.86  16.90   \n",
       "11   lr   51.33   60.88  -9.55        51.43        60.94        -9.51  19.16   \n",
       "8    lr   93.48  113.01 -19.53        93.29       113.06       -19.77  34.98   \n",
       "25   lr   89.33   89.08   0.25        89.46        89.28         0.18  19.84   \n",
       "41   lr   64.82   45.36  19.46        64.59        45.55        19.04  19.59   \n",
       "28   lr   41.98   31.75  10.23        42.01        31.74        10.27  14.98   \n",
       "4    lr   93.89  114.40 -20.51        93.74       114.55       -20.81  31.18   \n",
       "34   lr   77.88   67.73  10.15        77.95        67.37        10.58  24.70   \n",
       "1    lr   82.96  102.72 -19.76        83.07       102.79       -19.72  29.84   \n",
       "18   lr   48.94   49.10  -0.16        48.80        48.83        -0.03   9.73   \n",
       "19   ns   43.79   44.12  -0.33        43.53        44.12        -0.59  17.40   \n",
       "24   ns  109.57  109.23   0.34       109.32       109.56        -0.24  84.35   \n",
       "33   ns   62.12   52.18   9.94        62.21        52.10        10.11  23.83   \n",
       "27   ns   65.40   55.60   9.80        65.44        55.55         9.89  14.66   \n",
       "22   ns   79.12   79.04   0.08        79.32        79.18         0.14  67.12   \n",
       "15   ns   92.48  103.20 -10.72        93.28       103.41       -10.13  66.02   \n",
       "13   ns  103.35  113.00  -9.65       102.93       112.72        -9.79  71.14   \n",
       "39   ns  120.34  100.48  19.86       120.00       100.76        19.24  76.21   \n",
       "10   ns   37.92   47.60  -9.68        38.54        48.13        -9.59  34.56   \n",
       "7    ns   48.36   68.61 -20.25        48.76        68.63       -19.87  28.63   \n",
       "5    ns   44.20   64.67 -20.47        44.10        64.61       -20.51  25.47   \n",
       "42   ns   80.95   60.88  20.07        81.63        60.94        20.69  51.64   \n",
       "2    ns   53.68   73.64 -19.96        53.50        73.92       -20.42  31.06   \n",
       "38   ns   88.04   67.80  20.24        88.08        68.03        20.05  52.42   \n",
       "32   ns   54.11   43.55  10.56        54.53        44.00        10.53  49.73   \n",
       "37   rl  128.94  109.07  19.87       128.77       109.29        19.48  30.80   \n",
       "40   rl  107.68   88.16  19.52       107.54        88.07        19.47  29.20   \n",
       "35   rl  104.88   95.17   9.71       104.97        95.29         9.68  32.17   \n",
       "0    rl   89.78  110.56 -20.78        89.97       110.59       -20.62  44.07   \n",
       "29   rl  111.24  101.12  10.12       111.12       101.17         9.95  26.12   \n",
       "26   rl   84.62   84.52   0.10        84.62        84.50         0.12  24.89   \n",
       "23   rl   60.96   61.82  -0.86        60.79        61.89        -1.10  22.21   \n",
       "20   rl  100.33  100.76  -0.43       100.23       100.59        -0.36  10.59   \n",
       "17   rl  108.08  117.28  -9.20       107.97       117.34        -9.37  40.72   \n",
       "12   rl   73.98   84.53 -10.55        74.10        84.51       -10.41  16.48   \n",
       "9    rl  139.69  149.68  -9.99       139.73       149.80       -10.07  21.41   \n",
       "6    rl   56.71   76.26 -19.55        56.65        76.06       -19.41  22.53   \n",
       "3    rl   72.43   92.74 -20.31        72.56        92.61       -20.05  29.67   \n",
       "30   rl  124.15  114.46   9.69       124.34       114.45         9.89  33.35   \n",
       "44   rl   70.60   50.16  20.44        70.58        50.01        20.57  34.12   \n",
       "\n",
       "      SDB    SDD  complex_SDA  complex_SDB  complex_SDD  simple_skewness_A  \\\n",
       "16  18.85  14.58        33.69        19.53        14.16              -1.67   \n",
       "31   5.63  10.06        16.34         6.60         9.75              -1.58   \n",
       "21   8.45   9.60        18.59         9.34         9.26              -2.08   \n",
       "14  23.88   9.86        34.15        24.51         9.64              -1.58   \n",
       "43   9.77  14.61        25.01        10.53        14.49              -2.34   \n",
       "36  12.25   4.66        17.50        13.01         4.49              -1.76   \n",
       "11  14.11   5.05        19.95        14.56         5.39              -1.76   \n",
       "8   19.91  15.07        35.10        20.72        14.39              -2.20   \n",
       "25   4.77  15.08        20.62         5.71        14.91              -2.20   \n",
       "41   9.10  10.49        20.20        10.00        10.20              -1.67   \n",
       "28   9.81   5.18        15.74        10.61         5.12              -1.67   \n",
       "4   20.82  10.36        31.65        21.53        10.12              -1.76   \n",
       "34   9.95  14.75        25.20        10.78        14.42              -2.34   \n",
       "1   24.56   5.28        30.20        25.08         5.12              -2.08   \n",
       "18   5.20   4.53        10.47         6.15         4.32              -2.87   \n",
       "19  12.62   4.78        18.13        13.32         4.81              -0.72   \n",
       "24  69.75  14.60        83.41        69.37        14.03              -0.12   \n",
       "33   8.47  15.35        24.46         9.29        15.18               0.24   \n",
       "27   9.66   5.01        15.51        10.52         4.99              -0.87   \n",
       "22  56.91  10.21        67.02        56.97        10.05               0.32   \n",
       "15  51.51  14.51        65.25        51.90        13.35              -0.24   \n",
       "13  61.24   9.90        70.25        61.48         8.78               0.20   \n",
       "39  66.02  10.19        75.89        65.75        10.15              -0.49   \n",
       "10  29.90   4.66        34.45        29.78         4.67               0.58   \n",
       "7   13.37  15.26        28.97        13.91        15.06               0.32   \n",
       "5   15.35  10.13        25.97        16.28         9.69              -0.41   \n",
       "42  36.69  14.95        50.86        36.92        13.94              -0.37   \n",
       "2   25.58   5.48        31.75        26.03         5.72              -0.49   \n",
       "38  47.16   5.26        52.73        47.13         5.60               0.49   \n",
       "32  39.30  10.43        49.41        39.15        10.26               0.54   \n",
       "37  25.26   5.54        31.36        25.81         5.55               1.76   \n",
       "40  18.52  10.68        29.75        19.37        10.39               1.67   \n",
       "35  17.61  14.57        32.44        18.38        14.06               2.34   \n",
       "0   39.96   4.11        44.18        40.44         3.74               2.08   \n",
       "29  20.40   5.73        26.85        21.13         5.72               1.67   \n",
       "26  10.26  14.62        25.25        11.18        14.07               2.20   \n",
       "23  11.89  10.32        22.88        12.74        10.14               2.08   \n",
       "20   5.55   5.04        11.40         6.44         4.96               2.87   \n",
       "17  26.32  14.40        41.14        26.73        14.41               1.67   \n",
       "12   6.39  10.09        17.20         7.15        10.05               1.58   \n",
       "9   16.26   5.15        21.98        16.57         5.40               1.76   \n",
       "6    8.26  14.27        23.03         9.21        13.82               2.20   \n",
       "3   20.47   9.20        30.17        21.07         9.10               1.76   \n",
       "30  23.29  10.06        33.68        23.82         9.85               1.58   \n",
       "44  19.53  14.59        34.32        20.10        14.23               2.34   \n",
       "\n",
       "    complex_skewness_A  simple_skewness_B  complex_skewness_B  \\\n",
       "16               -0.83               2.34                1.73   \n",
       "31               -1.01               1.76                1.78   \n",
       "21               -1.56               2.49                2.41   \n",
       "14               -1.15               2.20                1.47   \n",
       "43               -1.14               1.76                1.63   \n",
       "36               -1.56               3.37                2.59   \n",
       "11               -1.25               4.69                3.12   \n",
       "8                -1.07               1.76                1.38   \n",
       "25               -1.70               1.85                1.93   \n",
       "41               -1.24               2.34                2.26   \n",
       "28               -1.29               1.58                1.53   \n",
       "4                -0.96               2.08                1.27   \n",
       "34               -1.15               3.37                2.58   \n",
       "1                -0.91               1.85                1.31   \n",
       "18               -2.16               2.08                2.07   \n",
       "19               -0.69              -0.49               -0.49   \n",
       "24               -0.13              -0.45               -0.45   \n",
       "33                0.24              -0.16               -0.17   \n",
       "27               -0.87              -0.54               -0.54   \n",
       "22                0.33               0.77                0.78   \n",
       "15               -0.23              -0.63               -0.63   \n",
       "13                0.19               0.41                0.41   \n",
       "39               -0.51              -0.24               -0.23   \n",
       "10                0.59               0.16                0.16   \n",
       "7                 0.33               0.28                0.28   \n",
       "5                -0.35              -0.28               -0.29   \n",
       "42               -0.37              -0.54               -0.49   \n",
       "2                -0.42              -0.68               -0.67   \n",
       "38                0.49               0.24                0.24   \n",
       "32                0.54               0.20                0.21   \n",
       "37                0.91              -3.37               -1.97   \n",
       "40                1.24              -2.34               -1.71   \n",
       "35                1.31              -3.37               -2.13   \n",
       "0                 0.91              -1.85               -0.87   \n",
       "29                1.64              -1.58               -1.37   \n",
       "26                1.40              -1.85               -1.82   \n",
       "23                1.54              -2.49               -1.96   \n",
       "20                2.53              -2.08               -1.96   \n",
       "17                0.77              -2.34               -1.61   \n",
       "12                1.54              -2.20               -2.16   \n",
       "9                 1.27              -4.69               -2.83   \n",
       "6                 1.45              -1.76               -1.74   \n",
       "3                 1.20              -2.08               -1.48   \n",
       "30                0.88              -1.76               -1.19   \n",
       "44                1.08              -1.76               -1.06   \n",
       "\n",
       "    simple_skewness_D  complex_skewness_D  \n",
       "16              -4.00               -2.55  \n",
       "31              -3.34               -2.79  \n",
       "21              -4.57               -3.97  \n",
       "14              -3.78               -2.62  \n",
       "43              -4.10               -2.77  \n",
       "36              -5.13               -4.15  \n",
       "11              -6.45               -4.37  \n",
       "8               -3.96               -2.45  \n",
       "25              -4.06               -3.63  \n",
       "41              -4.00               -3.50  \n",
       "28              -3.25               -2.82  \n",
       "4               -3.83               -2.23  \n",
       "34              -5.71               -3.73  \n",
       "1               -3.93               -2.22  \n",
       "18              -4.94               -4.23  \n",
       "19              -0.23               -0.20  \n",
       "24               0.33                0.32  \n",
       "33               0.40                0.41  \n",
       "27              -0.33               -0.33  \n",
       "22              -0.45               -0.45  \n",
       "15               0.39                0.40  \n",
       "13              -0.21               -0.22  \n",
       "39              -0.25               -0.28  \n",
       "10               0.42                0.42  \n",
       "7                0.04                0.05  \n",
       "5               -0.13               -0.07  \n",
       "42               0.17                0.12  \n",
       "2                0.18                0.25  \n",
       "38               0.25                0.25  \n",
       "32               0.34                0.33  \n",
       "37               5.13                2.88  \n",
       "40               4.00                2.95  \n",
       "35               5.71                3.44  \n",
       "0                3.93                1.77  \n",
       "29               3.25                3.02  \n",
       "26               4.06                3.22  \n",
       "23               4.57                3.50  \n",
       "20               4.94                4.49  \n",
       "17               4.00                2.39  \n",
       "12               3.78                3.70  \n",
       "9                6.45                4.10  \n",
       "6                3.96                3.20  \n",
       "3                3.83                2.67  \n",
       "30               3.34                2.07  \n",
       "44               4.10                2.14  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Ensure the columns are present in the merged_df DataFrame\n",
    "columns_to_check = ['skew','EVA', 'EVB', 'EVD',\n",
    "                    'complex_EVA', 'complex_EVB', 'complex_EVD',\n",
    "                    'SDA', 'SDB', 'SDD',\n",
    "                    'complex_SDA', 'complex_SDB', 'complex_SDD',\n",
    "                    'simple_skewness_A', 'complex_skewness_A', 'simple_skewness_B', 'complex_skewness_B',\n",
    "                    'simple_skewness_D', 'complex_skewness_D'\n",
    "                    ]\n",
    "\n",
    "# Check which columns are missing\n",
    "missing_columns = [col for col in columns_to_check if col not in final_df_new.columns]\n",
    "\n",
    "# Print missing columns\n",
    "print(f\"Missing columns: {missing_columns}\")\n",
    "\n",
    "# Select only the columns that are present\n",
    "columns_to_select = [col for col in columns_to_check if col in final_df_new.columns]\n",
    "\n",
    "df_selected = final_df_new[columns_to_select]\n",
    "\n",
    "df_selected_rounded = df_selected.applymap(lambda x: round(x, 2) if isinstance(x, (int, float)) else x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_selected_rounded.sort_values(by='skew', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "def Pweight(p, alpha=1, gamma=0.6):\n",
    "    if p >= 1:\n",
    "        return 1\n",
    "    elif p <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return math.exp(-alpha * ((-math.log(p)) ** gamma))\n",
    "    \n",
    "def apply_probability_weighting(probs):\n",
    "    weighted_probs = []\n",
    "    cumulative_prob = 0\n",
    "    for prob in probs:\n",
    "        # Since cumulative_prob + prob might exceed 1, ensure it does not\n",
    "        cumulative_prob_next = min(cumulative_prob + prob, 1)\n",
    "        weighted_prob = Pweight(cumulative_prob_next) - Pweight(cumulative_prob)\n",
    "        weighted_probs.append(weighted_prob)\n",
    "        cumulative_prob = cumulative_prob_next\n",
    "    return weighted_probs\n",
    "\n",
    "\n",
    "\n",
    "def calculate_EU(weighted_probs, outcomes):\n",
    "    return sum(w * o for w, o in zip(weighted_probs, outcomes))\n",
    "\n",
    "def validate_probabilities(probs):\n",
    "    # Check if all probabilities are within the valid range (0, 1]\n",
    "    return all(0 < p <= 1 for p in probs)\n",
    "\n",
    "def apply_probability_weighting_and_calculate_EUA(row):\n",
    "    # Extract the probabilities and outcomes from the row\n",
    "    probs = row[['complex_PA1', 'complex_PA2', 'complex_PA3', 'complex_PA4', 'complex_PA5', 'complex_PA6', 'complex_PA7']].astype(float).tolist()\n",
    "    outcomes = row[['complex_OA1', 'complex_OA2', 'complex_OA3', 'complex_OA4', 'complex_OA5', 'complex_OA6', 'complex_OA7']].astype(float).tolist()\n",
    "    \n",
    "    # Validate probabilities\n",
    "    if not validate_probabilities(probs):\n",
    "        # Invalid probabilities detected, return NaN or handle as desired\n",
    "        return np.nan\n",
    "    \n",
    "    # Apply the probability weighting function\n",
    "    weighted_probs = apply_probability_weighting(probs)\n",
    "    \n",
    "    # Calculate the expected utility\n",
    "    EUA = calculate_EU(weighted_probs, outcomes)\n",
    "    \n",
    "    return EUA\n",
    "\n",
    "def apply_probability_weighting_and_calculate_EUB(row):\n",
    "    # Extract the probabilities and outcomes from the row\n",
    "    probs = row[['complex_PB1', 'complex_PB2', 'complex_PB3', 'complex_PB4', 'complex_PB5', 'complex_PB6', 'complex_PB7']].astype(float).tolist()\n",
    "    outcomes = row[['complex_OB1', 'complex_OB2', 'complex_OB3', 'complex_OB4', 'complex_OB5', 'complex_OB6', 'complex_OB7']].astype(float).tolist()\n",
    "    \n",
    "    # Validate probabilities\n",
    "    if not validate_probabilities(probs):\n",
    "        # Invalid probabilities detected, return NaN or handle as desired\n",
    "        return np.nan\n",
    "    \n",
    "    # Apply the probability weighting function\n",
    "    weighted_probs = apply_probability_weighting(probs)\n",
    "    \n",
    "    # Calculate the expected utility\n",
    "    EUB = calculate_EU(weighted_probs, outcomes)\n",
    "    \n",
    "    return EUB\n",
    "\n",
    "def apply_probability_weighting_and_calculate_EUA_simple(row):\n",
    "    # Extract the probabilities and outcomes from the row\n",
    "    probs = row[['P_A1', 'P_A2']].astype(float).tolist()\n",
    "    outcomes = row[['O_A1', 'O_A2']].astype(float).tolist()\n",
    "    \n",
    "    # Validate probabilities\n",
    "    if not validate_probabilities(probs):\n",
    "        # Invalid probabilities detected, return NaN or handle as desired\n",
    "        return np.nan\n",
    "    \n",
    "    # Apply the probability weighting function\n",
    "    weighted_probs = apply_probability_weighting(probs)\n",
    "    \n",
    "    # Calculate the expected utility\n",
    "    EUA_simple = calculate_EU(weighted_probs, outcomes)\n",
    "    \n",
    "    return EUA_simple\n",
    "\n",
    "def apply_probability_weighting_and_calculate_EUB_simple(row):\n",
    "    # Extract the probabilities and outcomes from the row\n",
    "    probs = row[['P_B1', 'P_B2']].astype(float).tolist()\n",
    "    outcomes = row[['O_B1', 'O_B2']].astype(float).tolist()\n",
    "    \n",
    "    # Validate probabilities\n",
    "    if not validate_probabilities(probs):\n",
    "        # Invalid probabilities detected, return NaN or handle as desired\n",
    "        return np.nan\n",
    "    \n",
    "    # Apply the probability weighting function\n",
    "    weighted_probs = apply_probability_weighting(probs)\n",
    "    \n",
    "    # Calculate the expected utility\n",
    "    EUB_simple = calculate_EU(weighted_probs, outcomes)\n",
    "    \n",
    "    return EUB_simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nona = final_df_new.dropna()\n",
    "\n",
    "# Apply the functions row-wise to compute the new columns\n",
    "df_nona['EUA'] = df_nona.apply(apply_probability_weighting_and_calculate_EUA, axis=1)\n",
    "df_nona['EUB'] = df_nona.apply(apply_probability_weighting_and_calculate_EUB, axis=1)\n",
    "df_nona['EUA_simple'] = df_nona.apply(apply_probability_weighting_and_calculate_EUA_simple, axis=1)\n",
    "df_nona['EUB_simple'] = df_nona.apply(apply_probability_weighting_and_calculate_EUB_simple, axis=1)\n",
    "\n",
    "# Remove rows with NaN in EUA or EUB due to invalid probabilities, or handle as desired\n",
    "df_nona = df_nona.dropna(subset=['EUA', 'EUB', 'EUA_simple', 'EUB_simple'])\n",
    "\n",
    "# Compute the differences\n",
    "df_nona['EUD_CC'] = df_nona['EUA'] - df_nona['EUB']\n",
    "df_nona['EUD_SC'] = df_nona['EUA_simple'] - df_nona['EUB']\n",
    "df_nona['EUD_CS'] = df_nona['EUA'] - df_nona['EUB_simple']\n",
    "df_nona['EUD_SS'] = df_nona['EUA_simple'] - df_nona['EUB_simple']\n",
    "\n",
    "df_nona['after_diff_CC'] = df_nona['EUD_CC'] - df_nona['EVD']\n",
    "df_nona['after_diff_CS'] = df_nona['EUD_CS'] - df_nona['EVD']\n",
    "df_nona['after_diff_SC'] = df_nona['EUD_SC'] - df_nona['EVD']\n",
    "df_nona['after_diff_SS'] = df_nona['EUD_SS'] - df_nona['EVD']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_nona_sorted = df_nona.sort_values(by='skew', ascending=True)\n",
    "df_nona_sorted.to_csv('study3_trials_old.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jl/mx4l1z1j1kgd53hpj7770jlw0000gp/T/ipykernel_75417/3763124541.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_selected_rounded = df_selected.applymap(lambda x: round(x, 2) if isinstance(x, (int, float)) else x)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure the columns are present in the merged_df DataFrame\n",
    "columns_to_check = ['skew','EVA', 'EVB', 'EVD',\n",
    "                    'complex_EVA', 'complex_EVB', 'complex_EVD',\n",
    "                    'SDA', 'SDB', 'SDD',\n",
    "                    'complex_SDA', 'complex_SDB', 'complex_SDD',\n",
    "                    'simple_skewness_A', 'complex_skewness_A', 'simple_skewness_B', 'complex_skewness_B',\n",
    "                    'simple_skewness_D', 'complex_skewness_D',\n",
    "                    'after_diff_CC', 'after_diff_CS', 'after_diff_SC', 'after_diff_SS'\n",
    "                    ]\n",
    "\n",
    "# Check which columns are missing\n",
    "missing_columns = [col for col in columns_to_check if col not in df_nona.columns]\n",
    "\n",
    "# Print missing columns\n",
    "print(f\"Missing columns: {missing_columns}\")\n",
    "\n",
    "# Select only the columns that are present\n",
    "columns_to_select = [col for col in columns_to_check if col in df_nona.columns]\n",
    "\n",
    "df_selected = df_nona[columns_to_select]\n",
    "\n",
    "df_selected_rounded = df_selected.applymap(lambda x: round(x, 2) if isinstance(x, (int, float)) else x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_selected_rounded_sorted = df_selected_rounded.sort_values(by='skew', ascending=True)\n",
    "\n",
    "df_selected_rounded_sorted.to_csv('study3_trials_old_short.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "complex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
